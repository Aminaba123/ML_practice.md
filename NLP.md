### NLP Roadmap 

https://medium.com/pythoneers/nlp-roadmap-of-algorithms-from-bow-to-bert-762527ac1a19

- The automation of this type of method is very hectic sometimes because of the varied data length.

- The methods do not have the capability to have a relationship with the previous words.

#### Tokenization Technique

Every text data have sentences made from words. It is a process to break the text sentences into words called tokens and the process is known as tokenization.

#### Lemmatization Technique

This technique is used to get the root word of the tokens in the data i.e. the token is happily and the root word is happy. It is a very useful technique in text pre-processing. The process of getting the root word is the lemmatization process.

#### Stop Words
This is a process to remove the most common tokens used in the text data that makes the corpus/document heavy for predictive analysis.

#### Concept of Bag of Words, TF-IDF, and N-grams

These techniques are useful to store the meaning of the tokens in relationship with other tokens that will be useful for predictive machine learning models. Whenever we work with text data, we need numeric data so that the machine can understand. These methods are useful because they convert the text tokens to numeric values/vectors so that the machine learning models process this semantic information between the information.

